{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is based on sklearn's official tutorial [Working With Text Data](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#bags-of-words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the 20 newsgroups dataset\n",
    "The dataset is called “Twenty Newsgroups”. Here is the official description, quoted from the [website](http://people.csail.mit.edu/jrennie/20Newsgroups/):\n",
    "\n",
    "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. To the best of our knowledge, it was originally collected by Ken Lang, probably for his paper “Newsweeder: Learning to filter netnews,” though he does not explicitly mention this collection. The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering.\n",
    "\n",
    "In the following we will use the built-in dataset loader for 20 newsgroups from scikit-learn. Alternatively, it is possible to download the dataset manually from the website and use the [sklearn.datasets.load_files](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html#sklearn.datasets.load_files) function by pointing it to the 20news-bydate-train sub-folder of the uncompressed archive folder.\n",
    "\n",
    "In order to get faster execution times for this first example we will work on a partial dataset with only 4 categories out of the 20 available in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned dataset is a scikit-learn “bunch”: a simple holder object with fields that can be both accessed as python dict keys or object attributes for convenience, for instance the target_names holds the list of the requested category names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mappings between target_names and integer label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism                   0\n",
      "comp.graphics                 1\n",
      "sci.med                       2\n",
      "soc.religion.christian        3\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(twenty_train.target_names):\n",
    "    print(f'{x:25} {i:5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let’s print the first loaded file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n",
      "comp.graphics 1\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(twenty_train['data'][0].split('\\n')))\n",
    "print(twenty_train.target_names[twenty_train.target[0]], twenty_train.target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features from text files¶\n",
    "## Bag of Words\n",
    "The most intuitive way to do so is to use a bags of words representation:\n",
    "\n",
    "* Assign a fixed integer id to each word occurring in any document of the training set (for instance by building a dictionary from words to integer indices).\n",
    "\n",
    "* For each document #i, count the number of occurrences of each word w and store it in X[i, j] as the value of feature #j where j is the index of word w in the dictionary.\n",
    "\n",
    "<img src='images/bag_of_words.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing text with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preprocessing, tokenizing and filtering of stopwords are all included in [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), which builds a dictionary of features and transforms documents to feature vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) supports counts of N-grams of words or consecutive characters. Once fitted, the vectorizer has built a dictionary of feature indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get('algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from': 14887,\n",
       " 'sd345': 29022,\n",
       " 'city': 8696,\n",
       " 'ac': 4017,\n",
       " 'uk': 33256,\n",
       " 'michael': 21661,\n",
       " 'collier': 9031,\n",
       " 'subject': 31077,\n",
       " 'converting': 9805,\n",
       " 'images': 17366,\n",
       " 'to': 32493,\n",
       " 'hp': 16916,\n",
       " 'laserjet': 19780,\n",
       " 'iii': 17302,\n",
       " 'nntp': 23122,\n",
       " 'posting': 25663,\n",
       " 'host': 16881,\n",
       " 'hampton': 16082,\n",
       " 'organization': 23915,\n",
       " 'the': 32142,\n",
       " 'university': 33597,\n",
       " 'lines': 20253,\n",
       " '14': 587,\n",
       " 'does': 12051,\n",
       " 'anyone': 5201,\n",
       " 'know': 19458,\n",
       " 'of': 23610,\n",
       " 'good': 15576,\n",
       " 'way': 34755,\n",
       " 'standard': 30623,\n",
       " 'pc': 24651,\n",
       " 'application': 5285,\n",
       " 'pd': 24677,\n",
       " 'utility': 33915,\n",
       " 'convert': 9801,\n",
       " 'tif': 32391,\n",
       " 'img': 17389,\n",
       " 'tga': 32116,\n",
       " 'files': 14281,\n",
       " 'into': 18268,\n",
       " 'format': 14676,\n",
       " 'we': 34775,\n",
       " 'would': 35312,\n",
       " 'also': 4808,\n",
       " 'like': 20198,\n",
       " 'do': 12014,\n",
       " 'same': 28619,\n",
       " 'hpgl': 16927,\n",
       " 'plotter': 25361,\n",
       " 'please': 25337,\n",
       " 'email': 12833,\n",
       " 'any': 5195,\n",
       " 'response': 27836,\n",
       " 'is': 18474,\n",
       " 'this': 32270,\n",
       " 'correct': 9932,\n",
       " 'group': 15837,\n",
       " 'thanks': 32135,\n",
       " 'in': 17556,\n",
       " 'advance': 4378,\n",
       " 'programmer': 26175,\n",
       " 'computer': 9338,\n",
       " 'unit': 33572,\n",
       " 'tel': 31915,\n",
       " '071': 177,\n",
       " '477': 2326,\n",
       " '8000': 3062,\n",
       " 'x3769': 35416,\n",
       " 'london': 20459,\n",
       " 'fax': 14085,\n",
       " '8565': 3166,\n",
       " 'ec1v': 12541,\n",
       " '0hb': 230,\n",
       " 'ani': 5046,\n",
       " 'ms': 22366,\n",
       " 'uky': 33267,\n",
       " 'edu': 12626,\n",
       " 'aniruddha': 5062,\n",
       " 'deglurkar': 11001,\n",
       " 'help': 16418,\n",
       " 'splitting': 30464,\n",
       " 'trimming': 32915,\n",
       " 'region': 27378,\n",
       " 'along': 4788,\n",
       " 'mesh': 21550,\n",
       " 'kentucky': 19254,\n",
       " 'dept': 11193,\n",
       " 'math': 21153,\n",
       " 'sciences': 28899,\n",
       " '28': 1731,\n",
       " 'hi': 16550,\n",
       " 'have': 16254,\n",
       " 'problem': 26093,\n",
       " 'hope': 16833,\n",
       " 'some': 30173,\n",
       " 'gurus': 15949,\n",
       " 'can': 7766,\n",
       " 'me': 21322,\n",
       " 'solve': 30164,\n",
       " 'background': 6031,\n",
       " 'rectangular': 27238,\n",
       " 'uv': 33949,\n",
       " 'domain': 12075,\n",
       " 'mapping': 20985,\n",
       " '3d': 2148,\n",
       " 'bezier': 6574,\n",
       " 'patch': 24567,\n",
       " '2d': 1858,\n",
       " 'area': 5411,\n",
       " 'which': 34954,\n",
       " 'inside': 18016,\n",
       " 'loop': 20480,\n",
       " 'had': 16014,\n",
       " 'be': 6298,\n",
       " 'rendered': 27582,\n",
       " 'set': 29313,\n",
       " 'curve': 10471,\n",
       " 'segments': 29147,\n",
       " 'for': 14601,\n",
       " 'sake': 28580,\n",
       " 'notation': 23256,\n",
       " 'made': 20770,\n",
       " 'up': 33773,\n",
       " 'cells': 8153,\n",
       " 'my': 22541,\n",
       " 'has': 16216,\n",
       " 'split': 30462,\n",
       " 'individual': 17716,\n",
       " 'smaller': 29976,\n",
       " 'bounded': 7085,\n",
       " 'by': 7505,\n",
       " 'if': 17268,\n",
       " 'cell': 8150,\n",
       " 'wholly': 34992,\n",
       " 'then': 32164,\n",
       " 'it': 18551,\n",
       " 'output': 24079,\n",
       " 'as': 5549,\n",
       " 'whole': 34987,\n",
       " 'else': 12817,\n",
       " 'trivially': 32945,\n",
       " 'rejected': 27438,\n",
       " 'body': 6939,\n",
       " 'how': 16908,\n",
       " 'thiss': 32271,\n",
       " 'done': 12103,\n",
       " 'or': 23870,\n",
       " 'there': 32202,\n",
       " 'algo': 4687,\n",
       " 'somewhere': 30194,\n",
       " 'doing': 12065,\n",
       " 'appreciated': 5304,\n",
       " 'get': 15319,\n",
       " 'irritated': 18465,\n",
       " 'human': 16999,\n",
       " 'stay': 30701,\n",
       " 'cool': 9839,\n",
       " 'divine': 11944,\n",
       " 'djohnson': 11966,\n",
       " 'cs': 10324,\n",
       " 'ucsd': 33216,\n",
       " 'darin': 10667,\n",
       " 'johnson': 18893,\n",
       " 're': 27031,\n",
       " 'harrassed': 16194,\n",
       " 'at': 5698,\n",
       " 'work': 35255,\n",
       " 'could': 9992,\n",
       " 'use': 33858,\n",
       " 'prayers': 25765,\n",
       " 'cse': 10339,\n",
       " 'san': 28631,\n",
       " 'diego': 11499,\n",
       " '63': 2648,\n",
       " 'well': 34866,\n",
       " 'll': 20373,\n",
       " 'but': 7480,\n",
       " 'may': 21209,\n",
       " 'apply': 5289,\n",
       " 'other': 24020,\n",
       " 'people': 24784,\n",
       " 'so': 30068,\n",
       " 'post': 25646,\n",
       " 've': 34120,\n",
       " 'been': 6358,\n",
       " 'working': 35264,\n",
       " 'company': 9191,\n",
       " 'eight': 12703,\n",
       " 'years': 35587,\n",
       " 'various': 34083,\n",
       " 'engineering': 13051,\n",
       " 'jobs': 18863,\n",
       " 'female': 14166,\n",
       " 'yesterday': 35603,\n",
       " 'counted': 10004,\n",
       " 'and': 4992,\n",
       " 'realized': 27084,\n",
       " 'that': 32139,\n",
       " 'on': 23733,\n",
       " 'seven': 29333,\n",
       " 'different': 11520,\n",
       " 'occasions': 23548,\n",
       " 'sexually': 29352,\n",
       " 'dreaded': 12231,\n",
       " 'coming': 9110,\n",
       " 'back': 6024,\n",
       " 'today': 32506,\n",
       " 'what': 34923,\n",
       " 'boss': 7056,\n",
       " 'comes': 9098,\n",
       " 'ask': 5578,\n",
       " 'kind': 19370,\n",
       " 'question': 26709,\n",
       " 'your': 35648,\n",
       " 'should': 29578,\n",
       " 'person': 24895,\n",
       " 'bring': 7231,\n",
       " 'these': 32221,\n",
       " 'problems': 26097,\n",
       " 'he': 16302,\n",
       " 'she': 29455,\n",
       " 'not': 23250,\n",
       " 'seem': 29130,\n",
       " 'take': 31710,\n",
       " 'action': 4194,\n",
       " 'keep': 19210,\n",
       " 'going': 15545,\n",
       " 'higher': 16573,\n",
       " 'sexual': 29350,\n",
       " 'harrassment': 16195,\n",
       " 'need': 22774,\n",
       " 'tolerated': 32530,\n",
       " 'an': 4938,\n",
       " 'enormous': 13089,\n",
       " 'emotional': 12899,\n",
       " 'support': 31364,\n",
       " 'discuss': 11723,\n",
       " 'with': 35157,\n",
       " 'someone': 30180,\n",
       " 'they': 32233,\n",
       " 'are': 5410,\n",
       " 'trying': 32997,\n",
       " 'something': 30187,\n",
       " 'about': 3958,\n",
       " 'you': 35638,\n",
       " 'feel': 14135,\n",
       " 'perhaps': 24827,\n",
       " 'personnel': 24908,\n",
       " 'department': 11159,\n",
       " 'while': 34956,\n",
       " 'preserving': 25924,\n",
       " 'privacy': 26060,\n",
       " 'most': 22270,\n",
       " 'companies': 9188,\n",
       " 'will': 35057,\n",
       " 'want': 34660,\n",
       " 'deal': 10797,\n",
       " 'because': 6333,\n",
       " 'constant': 9614,\n",
       " 'anxiety': 5193,\n",
       " 'seriously': 29286,\n",
       " 'affect': 4431,\n",
       " 'effectively': 12659,\n",
       " 'employees': 12924,\n",
       " 'their': 32152,\n",
       " 'unclear': 33374,\n",
       " 'letter': 20054,\n",
       " 'inconceivable': 17622,\n",
       " 'management': 20906,\n",
       " 'remains': 27528,\n",
       " 'ignorant': 17283,\n",
       " 'employee': 12923,\n",
       " 'strife': 30973,\n",
       " 'even': 13491,\n",
       " 'after': 4471,\n",
       " 'miracle': 21859,\n",
       " 'notice': 23268,\n",
       " 'manager': 20907,\n",
       " 'did': 11493,\n",
       " 'attention': 5783,\n",
       " 'ups': 33807,\n",
       " 'indeed': 17666,\n",
       " 'ignore': 17287,\n",
       " 'entire': 13132,\n",
       " 'state': 30673,\n",
       " 'agency': 4496,\n",
       " 'willing': 35073,\n",
       " 'fight': 14265,\n",
       " 'check': 8380,\n",
       " 'lawyer': 19852,\n",
       " 'women': 35216,\n",
       " 'resource': 27816,\n",
       " 'center': 8159,\n",
       " 'etc': 13400,\n",
       " 'find': 14309,\n",
       " 'out': 24052,\n",
       " 'paster': 24555,\n",
       " 'priest': 26010,\n",
       " 'husband': 17055,\n",
       " 'judgemental': 19017,\n",
       " 'supportive': 31370,\n",
       " 'comforting': 9106,\n",
       " 'lot': 20517,\n",
       " 'healing': 16325,\n",
       " 'returned': 27926,\n",
       " '11': 336,\n",
       " '25': 1632,\n",
       " 'only': 23757,\n",
       " 'ever': 13503,\n",
       " 'single': 29769,\n",
       " 'already': 4805,\n",
       " 'left': 19951,\n",
       " 'lunch': 20631,\n",
       " '15': 677,\n",
       " 'no': 23123,\n",
       " 'one': 23741,\n",
       " 'bothered': 7065,\n",
       " 'call': 7714,\n",
       " 'building': 7391,\n",
       " 'though': 32297,\n",
       " 'number': 23363,\n",
       " 'was': 34703,\n",
       " 'posted': 25654,\n",
       " 'happens': 16136,\n",
       " 'honest': 16803,\n",
       " 'believe': 6430,\n",
       " 'due': 12354,\n",
       " 'gross': 15827,\n",
       " 'insensitivity': 18009,\n",
       " 'feelings': 14138,\n",
       " 'through': 32332,\n",
       " 'offices': 23636,\n",
       " 'tend': 31978,\n",
       " 'more': 22215,\n",
       " 'insensitive': 18008,\n",
       " 'than': 32131,\n",
       " 'normally': 23215,\n",
       " 'maybe': 21212,\n",
       " 'hustle': 17068,\n",
       " 'stress': 30954,\n",
       " 'happen': 16131,\n",
       " 'often': 23654,\n",
       " 'didn': 11495,\n",
       " 'realize': 27083,\n",
       " 'car': 7860,\n",
       " 'broken': 7265,\n",
       " 'come': 9093,\n",
       " 'wonder': 35218,\n",
       " 'why': 35006,\n",
       " 'go': 15511,\n",
       " 'make': 20862,\n",
       " 'stop': 30874,\n",
       " 'being': 6412,\n",
       " 'angry': 5041,\n",
       " 'ignored': 17288,\n",
       " 'laugh': 19819,\n",
       " 'once': 23736,\n",
       " 'went': 34876,\n",
       " 'off': 23614,\n",
       " 'without': 35168,\n",
       " 'our': 24046,\n",
       " 'who': 34982,\n",
       " 'paying': 24636,\n",
       " 'reason': 27103,\n",
       " 'mr': 22356,\n",
       " 'moderator': 22069,\n",
       " 'allows': 4766,\n",
       " 'latest': 19802,\n",
       " 'indulgence': 17737,\n",
       " 'turn': 33078,\n",
       " 'signs': 29690,\n",
       " 'age': 4492,\n",
       " 'closing': 8860,\n",
       " 'don': 12096,\n",
       " 'let': 20048,\n",
       " 'hateful': 16235,\n",
       " 'actions': 4195,\n",
       " 'harm': 16179,\n",
       " 'still': 30808,\n",
       " 'playground': 25324,\n",
       " 'bully': 7413,\n",
       " 'enjoy': 13068,\n",
       " 'seeing': 29124,\n",
       " 'hurt': 17050,\n",
       " 'cause': 8034,\n",
       " 'accept': 4039,\n",
       " 'opinions': 23815,\n",
       " 'imbecile': 17384,\n",
       " 'worthless': 35306,\n",
       " 'much': 22403,\n",
       " 'wiser': 35145,\n",
       " 'hold': 16743,\n",
       " 'great': 15743,\n",
       " 'esteem': 13379,\n",
       " 'luxury': 20663,\n",
       " 'day': 10752,\n",
       " 'bytes': 7517,\n",
       " 'swap': 31497,\n",
       " 's0612596': 28498,\n",
       " 'rug': 28425,\n",
       " 'nl': 23102,\n",
       " 'zwart': 35780,\n",
       " 'catholic': 8017,\n",
       " 'church': 8609,\n",
       " 'poland': 25461,\n",
       " 'faculteit': 13921,\n",
       " 'der': 11198,\n",
       " 'letteren': 20056,\n",
       " 'rijksuniversiteit': 28104,\n",
       " 'groningen': 15824,\n",
       " '10': 242,\n",
       " 'hello': 16413,\n",
       " 'writing': 35351,\n",
       " 'paper': 24382,\n",
       " 'role': 28256,\n",
       " '1989': 1097,\n",
       " 'tell': 31945,\n",
       " 'fill': 14285,\n",
       " 'recent': 27149,\n",
       " 'books': 7008,\n",
       " 'articles': 5530,\n",
       " 'english': 13055,\n",
       " 'german': 15305,\n",
       " 'french': 14842,\n",
       " 'important': 17508,\n",
       " 'concerning': 9379,\n",
       " 'abortion': 3954,\n",
       " 'law': 19841,\n",
       " 'religious': 27510,\n",
       " 'education': 12629,\n",
       " 'schools': 28877,\n",
       " 'birth': 6726,\n",
       " 'control': 9771,\n",
       " 'relation': 27456,\n",
       " 'government': 15618,\n",
       " 'thanx': 32138,\n",
       " 'masja': 21101,\n",
       " 'stanly': 30638,\n",
       " 'grok11': 15822,\n",
       " 'columbiasc': 9067,\n",
       " 'ncr': 22725,\n",
       " 'com': 9072,\n",
       " 'elder': 12731,\n",
       " 'brother': 7280,\n",
       " 'corp': 9925,\n",
       " 'columbia': 9066,\n",
       " 'sc': 28771,\n",
       " 'article': 5529,\n",
       " 'apr': 5340,\n",
       " '00': 0,\n",
       " '57': 2521,\n",
       " '41': 2203,\n",
       " '1993': 1102,\n",
       " '28246': 1742,\n",
       " 'athos': 5730,\n",
       " 'rutgers': 28473,\n",
       " 'rexlex': 27997,\n",
       " 'fnal': 14526,\n",
       " 'gov': 15612,\n",
       " 'writes': 35350,\n",
       " '01': 37,\n",
       " '56': 2513,\n",
       " '22824': 1540,\n",
       " 'shrum': 29610,\n",
       " 'hpfcso': 16926,\n",
       " 'fc': 14095,\n",
       " 'matt': 21176,\n",
       " '22': 1490,\n",
       " 'therefore': 32205,\n",
       " 'main': 20842,\n",
       " 'highways': 16585,\n",
       " 'many': 20978,\n",
       " 'invite': 18363,\n",
       " 'wedding': 34810,\n",
       " 'feast': 14109,\n",
       " 'hmmmmmm': 16703,\n",
       " 'sounds': 30250,\n",
       " 'theology': 32179,\n",
       " 'christ': 8544,\n",
       " 'odds': 23595,\n",
       " 'am': 4852,\n",
       " 'parable': 24395,\n",
       " 'jesus': 18774,\n",
       " 'tells': 31948,\n",
       " 'kingdom': 19383,\n",
       " 'heaven': 16358,\n",
       " 'unto': 33741,\n",
       " 'certain': 8197,\n",
       " 'king': 19382,\n",
       " 'marriage': 21060,\n",
       " 'his': 16642,\n",
       " 'son': 30199,\n",
       " 'clothes': 8863,\n",
       " 'were': 34879,\n",
       " 'customary': 10481,\n",
       " 'given': 15406,\n",
       " 'those': 32295,\n",
       " 'chose': 8525,\n",
       " 'attend': 5777,\n",
       " 'man': 20903,\n",
       " 'refused': 27352,\n",
       " 'wear': 34790,\n",
       " 'equalivant': 13239,\n",
       " 'righteousness': 28091,\n",
       " 'when': 34935,\n",
       " 'died': 11498,\n",
       " 'sins': 29785,\n",
       " 'provided': 26356,\n",
       " 'decision': 10874,\n",
       " 'put': 26570,\n",
       " 'vbv': 34111,\n",
       " 'lor': 20493,\n",
       " 'eeap': 12639,\n",
       " 'cwru': 10510,\n",
       " 'virgilio': 34360,\n",
       " 'dean': 10805,\n",
       " 'velasco': 34151,\n",
       " 'jr': 18983,\n",
       " 'arrogance': 5512,\n",
       " 'christians': 8559,\n",
       " 'case': 7965,\n",
       " 'western': 34896,\n",
       " 'reserve': 27768,\n",
       " 'univ': 33581,\n",
       " 'cleveland': 8795,\n",
       " 'ohio': 23662,\n",
       " 'usa': 33848,\n",
       " '2073': 1396,\n",
       " 'geneva': 15237,\n",
       " 'hayesstw': 16277,\n",
       " 'risc1': 28131,\n",
       " 'unisa': 33569,\n",
       " 'za': 35688,\n",
       " 'steve': 30776,\n",
       " 'hayes': 16276,\n",
       " 'similar': 29715,\n",
       " 'analogy': 4953,\n",
       " 'might': 21732,\n",
       " 'medical': 21386,\n",
       " 'doctor': 12026,\n",
       " 'believes': 6437,\n",
       " 'blood': 6863,\n",
       " 'transfusion': 32756,\n",
       " 'necessary': 22765,\n",
       " 'save': 28735,\n",
       " 'life': 20167,\n",
       " 'child': 8451,\n",
       " 'whose': 34999,\n",
       " 'parents': 24451,\n",
       " 'jehovah': 18729,\n",
       " 'witnesses': 35176,\n",
       " 'conscientious': 9557,\n",
       " 'objections': 23477,\n",
       " 'efforts': 12669,\n",
       " 'persuade': 24913,\n",
       " 'them': 32160,\n",
       " 'agree': 4529,\n",
       " 'perceived': 24793,\n",
       " 'arrogant': 5513,\n",
       " 'precisely': 25794,\n",
       " 'truth': 32989,\n",
       " 'otherwise': 24026,\n",
       " 'belief': 6426,\n",
       " 'irrelevant': 18452,\n",
       " 'here': 16482,\n",
       " 'matters': 21179,\n",
       " 'true': 32973,\n",
       " 'seen': 29135,\n",
       " 'foce': 14533,\n",
       " 'beliefs': 6427,\n",
       " 'carry': 7938,\n",
       " 'step': 30747,\n",
       " 'further': 15006,\n",
       " 'doctors': 12028,\n",
       " 'claim': 8713,\n",
       " 'infallible': 17784,\n",
       " 'generally': 15219,\n",
       " 'admit': 4330,\n",
       " 'conceivably': 9360,\n",
       " 'wrong': 35358,\n",
       " 'tranfusion': 32722,\n",
       " 'all': 4720,\n",
       " 'however': 16913,\n",
       " 'enough': 13091,\n",
       " 'confidence': 9461,\n",
       " 'conviction': 9816,\n",
       " 'genuine': 15261,\n",
       " 'concern': 9377,\n",
       " 'fallible': 13977,\n",
       " 'beings': 6413,\n",
       " 'must': 22509,\n",
       " 'acknowledge': 4153,\n",
       " 'possibility': 25640,\n",
       " 'say': 28755,\n",
       " 'such': 31180,\n",
       " 'doubts': 12166,\n",
       " 'reasonable': 27105,\n",
       " 'stand': 30621,\n",
       " 'convictions': 9817,\n",
       " 'electrical': 12746,\n",
       " 'eng': 13037,\n",
       " 'applied': 5287,\n",
       " 'physics': 25121,\n",
       " 'graduate': 15653,\n",
       " 'student': 31031,\n",
       " 'roboticist': 28207,\n",
       " 'training': 32709,\n",
       " 'wannabee': 34657,\n",
       " 'bullwinkle': 7412,\n",
       " 'intimidating': 18267,\n",
       " 'referee': 27307,\n",
       " 'very': 34229,\n",
       " 'doesn': 12052,\n",
       " 'look': 20470,\n",
       " 'jewish': 18779,\n",
       " 'carpenter': 7928,\n",
       " 'jodfishe': 18866,\n",
       " 'silver': 29706,\n",
       " 'ucs': 33213,\n",
       " 'indiana': 17687,\n",
       " 'joseph': 18929,\n",
       " 'dale': 10604,\n",
       " 'fisher': 14363,\n",
       " 'anger': 5030,\n",
       " '34': 2012,\n",
       " '17': 842,\n",
       " '44': 2258,\n",
       " '2232': 1512,\n",
       " 'news': 22944,\n",
       " 'cbnewsk': 8065,\n",
       " 'att': 5758,\n",
       " 'paul': 24616,\n",
       " 'conditt': 9428,\n",
       " 'insert': 18011,\n",
       " 'deletion': 11041,\n",
       " 'aaron': 3892,\n",
       " 'discourse': 11701,\n",
       " 'ref': 27304,\n",
       " 'galatians': 15060,\n",
       " '19': 966,\n",
       " '20': 1341,\n",
       " 'obvious': 23541,\n",
       " 'speaking': 30330,\n",
       " 'acts': 4211,\n",
       " 'flesh': 14440,\n",
       " 'just': 19076,\n",
       " 'emotions': 12902,\n",
       " 'themselves': 32163,\n",
       " 'moral': 22200,\n",
       " 'immoral': 17423,\n",
       " 'bad': 6057,\n",
       " 'first': 14357,\n",
       " 'label': 19649,\n",
       " 'emotion': 12898,\n",
       " 'numb': 23362,\n",
       " 'ourselves': 24050,\n",
       " 'hide': 16562,\n",
       " 'god': 15521,\n",
       " 'accepts': 4045,\n",
       " 'us': 33847,\n",
       " 'oh': 23660,\n",
       " 'definitely': 10983,\n",
       " 'colossians': 9056,\n",
       " 'ephesians': 13192,\n",
       " '27': 1700,\n",
       " 'controlled': 9774,\n",
       " 'puts': 26572,\n",
       " 'strong': 31000,\n",
       " 'emphasis': 12911,\n",
       " 'self': 29171,\n",
       " 'write': 35346,\n",
       " 'timothy': 32435,\n",
       " 'making': 20868,\n",
       " 'sure': 31394,\n",
       " 'teach': 31849,\n",
       " 'remainder': 27525,\n",
       " 'paragraph': 24411,\n",
       " 'think': 32253,\n",
       " 'quick': 26724,\n",
       " 'judge': 19014,\n",
       " 'forgiven': 14656,\n",
       " 'aids': 4566,\n",
       " 'dealt': 10802,\n",
       " 'taken': 31711,\n",
       " 'responsibility': 27840,\n",
       " 'appropriate': 5319,\n",
       " 'choices': 8499,\n",
       " 'read': 27049,\n",
       " 'yourself': 35651,\n",
       " 'joe': 18869,\n",
       " 'again': 4486,\n",
       " 'issue': 18542,\n",
       " 'especially': 13351,\n",
       " 'over': 24108,\n",
       " 'stem': 30741,\n",
       " 'instances': 18051,\n",
       " 'giving': 15408,\n",
       " 'soon': 30208,\n",
       " 'moore': 22193,\n",
       " 'aldridge': 4661,\n",
       " 'netcom': 22861,\n",
       " 'jacquelin': 18627,\n",
       " 'teenage': 31893,\n",
       " 'acne': 4165,\n",
       " 'line': 20242,\n",
       " 'communication': 9171,\n",
       " 'services': 29306,\n",
       " '408': 2198,\n",
       " '241': 1599,\n",
       " '9760': 3432,\n",
       " 'guest': 15907,\n",
       " 'pchurch': 24668,\n",
       " 'swell': 31528,\n",
       " 'actrix': 4210,\n",
       " 'gen': 15195,\n",
       " 'nz': 23432,\n",
       " 'pat': 24565,\n",
       " 'churchill': 8612,\n",
       " 'usual': 33889,\n",
       " 'spotty': 30494,\n",
       " 'chin': 8470,\n",
       " 'greasy': 15742,\n",
       " 'nose': 23240,\n",
       " 'bought': 7073,\n",
       " 'him': 16603,\n",
       " 'clearasil': 8777,\n",
       " 'face': 13892,\n",
       " 'wash': 34705,\n",
       " 'ointment': 23671,\n",
       " 'probably': 26085,\n",
       " 'diet': 11505,\n",
       " 'product': 26136,\n",
       " 'called': 7718,\n",
       " 'dalacin': 10602,\n",
       " 'used': 33860,\n",
       " 'prescription': 25907,\n",
       " 'treatment': 32847,\n",
       " 'available': 5906,\n",
       " 'chemist': 8406,\n",
       " 'counter': 10006,\n",
       " 'asked': 5580,\n",
       " 'couple': 10028,\n",
       " 'pharmacists': 24998,\n",
       " 'either': 12711,\n",
       " 'severe': 29337,\n",
       " 'ok': 23674,\n",
       " 'odd': 23589,\n",
       " 'spots': 30493,\n",
       " 'teenager': 31894,\n",
       " 'nothing': 23264,\n",
       " 'serious': 29285,\n",
       " 'father': 14060,\n",
       " 'figure': 14272,\n",
       " 'escalate': 13330,\n",
       " 'disfiguring': 11735,\n",
       " 'kids': 19336,\n",
       " 'senstitive': 29229,\n",
       " 'appearance': 5267,\n",
       " 'wary': 34702,\n",
       " 'neighbour': 22816,\n",
       " 'wierd': 35031,\n",
       " 'malady': 20873,\n",
       " 'eventually': 13501,\n",
       " 'down': 12176,\n",
       " 'overdose': 24121,\n",
       " 'vitamin': 34417,\n",
       " 'scaliness': 28779,\n",
       " 'around': 5489,\n",
       " 'hairline': 16038,\n",
       " 'scalp': 28783,\n",
       " 'sort': 30233,\n",
       " 'cradle': 10109,\n",
       " 'cap': 7820,\n",
       " 'pointers': 25445,\n",
       " 'advice': 4399,\n",
       " 'tried': 32898,\n",
       " 'anti': 5138,\n",
       " 'dandruff': 10633,\n",
       " 'shampoos': 29412,\n",
       " 'inclined': 17601,\n",
       " 'condition': 9423,\n",
       " 'worse': 35295,\n",
       " 'better': 6557,\n",
       " 'shall': 29399,\n",
       " 'bury': 7463,\n",
       " 'kid': 19330,\n",
       " 'till': 32409,\n",
       " '21': 1421,\n",
       " 'lucky': 20599,\n",
       " 'ones': 23746,\n",
       " 'little': 20342,\n",
       " 'luck': 20597,\n",
       " 'skin': 29864,\n",
       " 'gets': 15322,\n",
       " 'oily': 23668,\n",
       " 'really': 27088,\n",
       " 'miserable': 21898,\n",
       " 'pimples': 25200,\n",
       " 'dry': 12294,\n",
       " 'frequent': 14848,\n",
       " 'lukewarm': 20613,\n",
       " 'water': 34727,\n",
       " 'rinses': 28120,\n",
       " 'getting': 15323,\n",
       " 'thing': 32249,\n",
       " 'under': 33410,\n",
       " 'simple': 29724,\n",
       " 'submerging': 31093,\n",
       " 'bathwater': 6253,\n",
       " 'softened': 30112,\n",
       " 'washing': 34709,\n",
       " 'taking': 31716,\n",
       " 'mineral': 21814,\n",
       " 'heard': 16336,\n",
       " 'iodine': 18380,\n",
       " 'causes': 8037,\n",
       " 'trouble': 32962,\n",
       " 'fast': 14048,\n",
       " 'food': 14581,\n",
       " 'restaurants': 27850,\n",
       " 'sterilize': 30766,\n",
       " 'equipment': 13256,\n",
       " 'where': 34938,\n",
       " 'foods': 14583,\n",
       " 'came': 7746,\n",
       " 'grease': 15741,\n",
       " 'immediately': 17410,\n",
       " 'removed': 27567,\n",
       " 'eating': 12524,\n",
       " 'meat': 21356,\n",
       " 'keeping': 19213,\n",
       " 'hair': 16036,\n",
       " 'rinse': 28119,\n",
       " 'mousse': 22315,\n",
       " 'dip': 11599,\n",
       " 'spray': 30502,\n",
       " 'warm': 34672,\n",
       " 'bath': 6248,\n",
       " 'soaks': 30071,\n",
       " 'cloths': 8865,\n",
       " 'soften': 30111,\n",
       " 'oil': 23667,\n",
       " 'pores': 25580,\n",
       " 'prevent': 25983,\n",
       " 'blackheads': 6774,\n",
       " 'hydrophilic': 17093,\n",
       " 'loves': 20543,\n",
       " 'softens': 30113,\n",
       " 'washes': 34708,\n",
       " 'chance': 8278,\n",
       " 'goes': 15541,\n",
       " 'limp': 20226,\n",
       " 'oilyness': 23669,\n",
       " 'becoming': 6342,\n",
       " 'convinced': 9820,\n",
       " 'best': 6540,\n",
       " 'whitehead': 34973,\n",
       " 'leave': 19926,\n",
       " 'alone': 4787,\n",
       " 'days': 10760,\n",
       " 'pimple': 25199,\n",
       " 'misery': 21901,\n",
       " 'prying': 26386,\n",
       " 'black': 6773,\n",
       " 'whiteheads': 34974,\n",
       " 'infections': 17796,\n",
       " 'red': 27255,\n",
       " 'usually': 33891,\n",
       " 'break': 7167,\n",
       " 'naturally': 22686,\n",
       " 'won': 35217,\n",
       " 'infection': 17795,\n",
       " 'afterwards': 4479,\n",
       " 'normal': 23210,\n",
       " 'cosmetic': 9970,\n",
       " 'industry': 17742,\n",
       " 'makes': 20866,\n",
       " 'money': 22135,\n",
       " 'selling': 29180,\n",
       " 'idea': 17219,\n",
       " 'incredible': 17650,\n",
       " 'defect': 10949,\n",
       " 'hidden': 16561,\n",
       " 'cost': 9981,\n",
       " 'causing': 8039,\n",
       " 'jackie': 18618,\n",
       " 'geb': 15173,\n",
       " 'pitt': 25234,\n",
       " 'gordon': 15591,\n",
       " 'banks': 6140,\n",
       " 'blindsight': 6838,\n",
       " 'reply': 27664,\n",
       " 'pittsburgh': 25237,\n",
       " 'science': 28897,\n",
       " '18': 896,\n",
       " 'werner': 34881,\n",
       " '240393161954': 1594,\n",
       " 'tol7mac15': 32522,\n",
       " 'soe': 30105,\n",
       " 'berkeley': 6507,\n",
       " 'john': 18880,\n",
       " '19213': 995,\n",
       " 'uucp': 33940,\n",
       " 'wrote': 35363,\n",
       " 'explain': 13733,\n",
       " 'thought': 32298,\n",
       " 'types': 33142,\n",
       " 'cones': 9444,\n",
       " 'equivalent': 13259,\n",
       " 'rgb': 28011,\n",
       " 'basically': 6223,\n",
       " 'right': 28089,\n",
       " 'sensitive': 29222,\n",
       " 'green': 15755,\n",
       " 'blue': 6882,\n",
       " 'yellow': 35597,\n",
       " 'two': 33125,\n",
       " 'common': 9158,\n",
       " 'kinds': 19378,\n",
       " 'color': 9045,\n",
       " 'blindness': 6836,\n",
       " 'yes': 35601,\n",
       " 'remember': 27543,\n",
       " 'now': 23301,\n",
       " 'contrary': 9748,\n",
       " 'original': 23940,\n",
       " 'respondent': 27832,\n",
       " 'claimed': 8715,\n",
       " 'n3jxp': 22582,\n",
       " 'skepticism': 29848,\n",
       " 'chastity': 8362,\n",
       " 'intellect': 18117,\n",
       " 'cadre': 7665,\n",
       " 'dsl': 12307,\n",
       " 'shameful': 29408,\n",
       " 'surrender': 31424,\n",
       " 'too': 32570,\n",
       " 'libman': 20133,\n",
       " 'hsc': 16954,\n",
       " 'usc': 33853,\n",
       " 'marlena': 21053,\n",
       " 'patient': 24593,\n",
       " 'relationship': 27459,\n",
       " 'southern': 30259,\n",
       " 'california': 7711,\n",
       " 'los': 20506,\n",
       " 'angeles': 5026,\n",
       " 'ca': 7643,\n",
       " '64': 2667,\n",
       " 'situation': 29813,\n",
       " 'occurred': 23566,\n",
       " 'between': 6561,\n",
       " 'physican': 25115,\n",
       " 'upset': 33808,\n",
       " 'saw': 28747,\n",
       " 'recurring': 27248,\n",
       " 'pain': 24296,\n",
       " 'suggested': 31218,\n",
       " 'medication': 21389,\n",
       " 'course': 10037,\n",
       " 'told': 32523,\n",
       " 'begin': 6381,\n",
       " 'monitor': 22140,\n",
       " 'its': 18585,\n",
       " 'effectiveness': 12660,\n",
       " 'general': 15209,\n",
       " 'health': 16328,\n",
       " 'exactly': 13552,\n",
       " 'reaching': 27038,\n",
       " 'secretary': 29094,\n",
       " 'explained': 13737,\n",
       " 'her': 16470,\n",
       " 'following': 14565,\n",
       " 'request': 27727,\n",
       " 'worried': 35290,\n",
       " 'episodes': 13215,\n",
       " 'effective': 12658,\n",
       " 'words': 35249,\n",
       " 'whatever': 34924,\n",
       " 'busy': 7479,\n",
       " 'time': 32417,\n",
       " 'chit': 8493,\n",
       " 'chat': 8363,\n",
       " 'simply': 29736,\n",
       " 'instructions': 18080,\n",
       " '7th': 3052,\n",
       " 'status': 30696,\n",
       " 'feeling': 14137,\n",
       " 'talk': 31723,\n",
       " 'responded': 27831,\n",
       " 'spit': 30445,\n",
       " 'said': 28573,\n",
       " 'raised': 26849,\n",
       " 'voice': 34463,\n",
       " 'started': 30661,\n",
       " 'quickly': 26727,\n",
       " 'nervousness': 22847,\n",
       " 'interfered': 18176,\n",
       " 'choice': 8498,\n",
       " 'stuttered': 31052,\n",
       " ...}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From occurrences to frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occurrence count is a good start but there is an issue: longer documents will have higher average count values than shorter documents, even though they might talk about the same topics.\n",
    "\n",
    "To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called tf for Term Frequencies.\n",
    "\n",
    "Another refinement on top of tf is to downscale weights for words that occur in many documents in the corpus and are therefore less informative than those that occur only in a smaller portion of the corpus.\n",
    "\n",
    "This downscaling is called [tf–idf](https://en.wikipedia.org/wiki/Tf-idf) for “Term Frequency times Inverse Document Frequency”.\n",
    "\n",
    "Both tf and tf–idf can be computed as follows using [TfidfTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer):\n",
    "\n",
    "<img src='images/TF-IDF.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a linear [support vector machine (SVM)](https://scikit-learn.org/stable/modules/svm.html#svm)\n",
    "\n",
    "<img src='images/svm.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9101198402130493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None)),\n",
    " ])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = text_clf.predict(twenty_test['data'])\n",
    "print(f'Test Accuracy: {np.mean(predicted == twenty_test.target)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.80      0.87       319\n",
      "         comp.graphics       0.87      0.98      0.92       389\n",
      "               sci.med       0.94      0.89      0.91       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "              accuracy                           0.91      1502\n",
      "             macro avg       0.91      0.91      0.91      1502\n",
      "          weighted avg       0.91      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter tuning using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "     'tfidf__use_idf': (True, False),\n",
    "     'clf__alpha': (1e-2, 1e-3),\n",
    " }\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "<img src='images/crossValidation.png'>\n",
    "\n",
    "### Grid Search\n",
    "<img src='images/gs.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9641116526362428\n",
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'Best Score: {gs_clf.best_score_}')\n",
    "for param_name in sorted(parameters.keys()):\n",
    "     print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_vect__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.105948</td>\n",
       "      <td>0.024078</td>\n",
       "      <td>0.250149</td>\n",
       "      <td>0.012674</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': True, '...</td>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.915929</td>\n",
       "      <td>0.858407</td>\n",
       "      <td>0.887168</td>\n",
       "      <td>0.908686</td>\n",
       "      <td>0.894993</td>\n",
       "      <td>0.020614</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.668365</td>\n",
       "      <td>0.059414</td>\n",
       "      <td>0.586363</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>0.01</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': True, '...</td>\n",
       "      <td>0.935841</td>\n",
       "      <td>0.926991</td>\n",
       "      <td>0.891593</td>\n",
       "      <td>0.911504</td>\n",
       "      <td>0.913140</td>\n",
       "      <td>0.915817</td>\n",
       "      <td>0.015099</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.078371</td>\n",
       "      <td>0.012068</td>\n",
       "      <td>0.232094</td>\n",
       "      <td>0.010825</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': False, ...</td>\n",
       "      <td>0.820796</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.747788</td>\n",
       "      <td>0.803097</td>\n",
       "      <td>0.781737</td>\n",
       "      <td>0.788214</td>\n",
       "      <td>0.024345</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.685271</td>\n",
       "      <td>0.114849</td>\n",
       "      <td>0.607813</td>\n",
       "      <td>0.022694</td>\n",
       "      <td>0.01</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.01, 'tfidf__use_idf': False, ...</td>\n",
       "      <td>0.825221</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.823009</td>\n",
       "      <td>0.804009</td>\n",
       "      <td>0.807266</td>\n",
       "      <td>0.018295</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.139356</td>\n",
       "      <td>0.036813</td>\n",
       "      <td>0.290371</td>\n",
       "      <td>0.010768</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': True, ...</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.962389</td>\n",
       "      <td>0.957965</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.971047</td>\n",
       "      <td>0.964112</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.239864</td>\n",
       "      <td>0.019556</td>\n",
       "      <td>0.575046</td>\n",
       "      <td>0.073604</td>\n",
       "      <td>0.001</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': True, ...</td>\n",
       "      <td>0.966814</td>\n",
       "      <td>0.962389</td>\n",
       "      <td>0.951327</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>0.959911</td>\n",
       "      <td>0.959238</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.284911</td>\n",
       "      <td>0.078157</td>\n",
       "      <td>0.308939</td>\n",
       "      <td>0.055807</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': False,...</td>\n",
       "      <td>0.915929</td>\n",
       "      <td>0.896018</td>\n",
       "      <td>0.911504</td>\n",
       "      <td>0.904867</td>\n",
       "      <td>0.935412</td>\n",
       "      <td>0.912716</td>\n",
       "      <td>0.013153</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.018627</td>\n",
       "      <td>0.164027</td>\n",
       "      <td>0.323899</td>\n",
       "      <td>0.047419</td>\n",
       "      <td>0.001</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'clf__alpha': 0.001, 'tfidf__use_idf': False,...</td>\n",
       "      <td>0.931416</td>\n",
       "      <td>0.922566</td>\n",
       "      <td>0.918142</td>\n",
       "      <td>0.926991</td>\n",
       "      <td>0.933185</td>\n",
       "      <td>0.926451</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.105948      0.024078         0.250149        0.012674   \n",
       "1       3.668365      0.059414         0.586363        0.016104   \n",
       "2       1.078371      0.012068         0.232094        0.010825   \n",
       "3       3.685271      0.114849         0.607813        0.022694   \n",
       "4       1.139356      0.036813         0.290371        0.010768   \n",
       "5       4.239864      0.019556         0.575046        0.073604   \n",
       "6       1.284911      0.078157         0.308939        0.055807   \n",
       "7       3.018627      0.164027         0.323899        0.047419   \n",
       "\n",
       "  param_clf__alpha param_tfidf__use_idf param_vect__ngram_range  \\\n",
       "0             0.01                 True                  (1, 1)   \n",
       "1             0.01                 True                  (1, 2)   \n",
       "2             0.01                False                  (1, 1)   \n",
       "3             0.01                False                  (1, 2)   \n",
       "4            0.001                 True                  (1, 1)   \n",
       "5            0.001                 True                  (1, 2)   \n",
       "6            0.001                False                  (1, 1)   \n",
       "7            0.001                False                  (1, 2)   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf__alpha': 0.01, 'tfidf__use_idf': True, '...           0.904867   \n",
       "1  {'clf__alpha': 0.01, 'tfidf__use_idf': True, '...           0.935841   \n",
       "2  {'clf__alpha': 0.01, 'tfidf__use_idf': False, ...           0.820796   \n",
       "3  {'clf__alpha': 0.01, 'tfidf__use_idf': False, ...           0.825221   \n",
       "4  {'clf__alpha': 0.001, 'tfidf__use_idf': True, ...           0.964602   \n",
       "5  {'clf__alpha': 0.001, 'tfidf__use_idf': True, ...           0.966814   \n",
       "6  {'clf__alpha': 0.001, 'tfidf__use_idf': False,...           0.915929   \n",
       "7  {'clf__alpha': 0.001, 'tfidf__use_idf': False,...           0.931416   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.915929           0.858407           0.887168           0.908686   \n",
       "1           0.926991           0.891593           0.911504           0.913140   \n",
       "2           0.787611           0.747788           0.803097           0.781737   \n",
       "3           0.809735           0.774336           0.823009           0.804009   \n",
       "4           0.962389           0.957965           0.964602           0.971047   \n",
       "5           0.962389           0.951327           0.955752           0.959911   \n",
       "6           0.896018           0.911504           0.904867           0.935412   \n",
       "7           0.922566           0.918142           0.926991           0.933185   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.894993        0.020614                6  \n",
       "1         0.915817        0.015099                4  \n",
       "2         0.788214        0.024345                8  \n",
       "3         0.807266        0.018295                7  \n",
       "4         0.964112        0.004222                1  \n",
       "5         0.959238        0.005342                2  \n",
       "6         0.912716        0.013153                5  \n",
       "7         0.926451        0.005556                3  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(gs_clf.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
